Experiment: base_train
Logger directory: logs/base_train
2023-10-24 10:31:03 ==> Namespace(folder='/kaggle/input/shapenet', json='final.json', b_tag='depth', log_dir='logs', exp='base_train', batch_size=24, size=256, latent_dim=1024, epoch=0, scheduler='step', gamma=0.5, n_epochs=30, decay_epoch=10, save_iter=100, lr=0.0001, gpu=0, modelPath=None, pcn='weights/pcn_base/model.pth', test=False, testSave=False, resume=False, lambda_pixel=10, lambda_latent=0.5, lambda_kl=0.01)
2023-10-24 10:31:03 ==> ------------------Epoch: 0------------------
2023-10-24 11:38:55 ==> Epoch 0 Train Loss: 65.70007925387472
2023-10-24 11:47:31 ==> Epoch 0 Val Loss: 40.71485057473183 Learning Rate: 5e-05
2023-10-24 11:47:32 ==> Epoch 0 Best Model Saved
2023-10-24 11:47:32 ==> Last Model saved (best loss 40.7149 at epoch 0)
2023-10-24 11:47:32 ==> ------------------Epoch: 1------------------
2023-10-24 12:51:00 ==> Epoch 1 Train Loss: 57.58647069800645
2023-10-24 12:57:45 ==> Epoch 1 Val Loss: 38.851092448458076 Learning Rate: 2.5e-05
2023-10-24 12:57:46 ==> Epoch 1 Best Model Saved
2023-10-24 12:57:46 ==> Last Model saved (best loss 38.8511 at epoch 1)
2023-10-24 12:57:46 ==> ------------------Epoch: 2------------------
2023-10-24 13:58:09 ==> Epoch 2 Train Loss: 55.40630198200233
2023-10-24 14:05:02 ==> Epoch 2 Val Loss: 53.14447284210473 Learning Rate: 1.25e-05
2023-10-24 14:05:02 ==> Last Model saved (best loss 38.8511 at epoch 1)
2023-10-24 14:05:02 ==> ------------------Epoch: 3------------------
2023-10-24 15:04:24 ==> Epoch 3 Train Loss: 54.326120940968394
2023-10-24 15:11:06 ==> Epoch 3 Val Loss: 35.73006298625842 Learning Rate: 6.25e-06
2023-10-24 15:11:06 ==> Epoch 3 Best Model Saved
2023-10-24 15:11:06 ==> Last Model saved (best loss 35.7301 at epoch 3)
2023-10-24 15:11:06 ==> ------------------Epoch: 4------------------
2023-10-24 16:11:29 ==> Epoch 4 Train Loss: 53.802360511617735
2023-10-24 16:17:58 ==> Epoch 4 Val Loss: 717.6302497601137 Learning Rate: 3.125e-06
2023-10-24 16:17:59 ==> Last Model saved (best loss 35.7301 at epoch 3)
2023-10-24 16:17:59 ==> ------------------Epoch: 5------------------
2023-10-24 17:17:24 ==> Epoch 5 Train Loss: 53.52983511518687
2023-10-24 17:23:49 ==> Epoch 5 Val Loss: 35.8546913578175 Learning Rate: 1.5625e-06
2023-10-24 17:23:49 ==> Last Model saved (best loss 35.7301 at epoch 3)
2023-10-24 17:23:49 ==> ------------------Epoch: 6------------------
2023-10-24 18:27:40 ==> Epoch 6 Train Loss: 53.57931426377036
2023-10-24 18:34:49 ==> Epoch 6 Val Loss: 35.30104213277809 Learning Rate: 7.8125e-07
2023-10-24 18:34:49 ==> Epoch 6 Best Model Saved
2023-10-24 18:34:50 ==> Last Model saved (best loss 35.3010 at epoch 6)
2023-10-24 18:34:50 ==> ------------------Epoch: 7------------------
2023-10-24 19:39:00 ==> Epoch 7 Train Loss: 53.39643499464728
2023-10-24 19:46:01 ==> Epoch 7 Val Loss: 228.29337621107697 Learning Rate: 3.90625e-07
2023-10-24 19:46:01 ==> Last Model saved (best loss 35.3010 at epoch 6)
2023-10-24 19:46:01 ==> ------------------Epoch: 8------------------
2023-10-24 20:50:42 ==> Epoch 8 Train Loss: 53.41700586723164
2023-10-24 20:57:47 ==> Epoch 8 Val Loss: 83.82922058459371 Learning Rate: 1.953125e-07
2023-10-24 20:57:48 ==> Last Model saved (best loss 35.3010 at epoch 6)
2023-10-24 20:57:48 ==> ------------------Epoch: 9------------------
2023-10-24 22:02:19 ==> Epoch 9 Train Loss: 53.450871135573834
2023-10-24 22:09:17 ==> Epoch 9 Val Loss: 35.15674098976888 Learning Rate: 9.765625e-08
2023-10-24 22:09:17 ==> Epoch 9 Best Model Saved
2023-10-24 22:09:18 ==> Last Model saved (best loss 35.1567 at epoch 9)
2023-10-24 22:09:18 ==> ------------------Epoch: 10------------------

Experiment: base
Logger directory: logs/base
2023-10-25 07:06:43 ==> Namespace(folder='/kaggle/input/shapenet', json='final.json', b_tag='depth', log_dir='logs', exp='base', batch_size=24, size=256, latent_dim=1024, epoch=0, scheduler='step', gamma=0.8, n_epochs=18, decay_epoch=10, save_iter=1000, lr=1e-05, gpu=0, modelPath='weights/base/model.pth', pcn='weights/pcn_base/model.pth', test=False, testSave=False, resume=True, lambda_coarse=0.2, lambda_pixel=10, lambda_latent=0.8, lambda_kl=0.01)
2023-10-25 07:06:43 ==> Loading checkpoint from weights/base/model.pth
2023-10-25 07:06:43 ==> Checkpoint loaded (epoch 9, loss 35.15674098976888)
2023-10-25 07:06:43 ==> ------------------Epoch: 10------------------
2023-10-25 08:16:13 ==> Epoch 10 Train Loss: 25.100733570870943
2023-10-25 08:23:56 ==> Epoch 10 Val Loss: 48.651333732996136 Learning Rate: 8.000000000000001e-06
2023-10-25 08:23:56 ==> Epoch 10 Best Model Saved
2023-10-25 08:23:57 ==> Last Model saved (best loss 48.6513 at epoch 10)
2023-10-25 08:23:57 ==> ------------------Epoch: 11------------------
2023-10-25 09:20:52 ==> Epoch 11 Train Loss: 25.033646963420324
2023-10-25 09:27:07 ==> Epoch 11 Val Loss: 40.500898328609765 Learning Rate: 6.400000000000001e-06
2023-10-25 09:27:07 ==> Epoch 11 Best Model Saved
2023-10-25 09:27:07 ==> Last Model saved (best loss 40.5009 at epoch 11)
2023-10-25 09:27:07 ==> ------------------Epoch: 12------------------
2023-10-25 10:24:00 ==> Epoch 12 Train Loss: 24.92922441160772
2023-10-25 10:30:24 ==> Epoch 12 Val Loss: 39.52495661331341 Learning Rate: 5.120000000000002e-06
2023-10-25 10:30:25 ==> Epoch 12 Best Model Saved
2023-10-25 10:30:25 ==> Last Model saved (best loss 39.5250 at epoch 12)
2023-10-25 10:30:25 ==> ------------------Epoch: 13------------------
2023-10-25 11:28:10 ==> Epoch 13 Train Loss: 24.91629396507051
2023-10-25 11:34:35 ==> Epoch 13 Val Loss: 134.42220981465653 Learning Rate: 4.096000000000002e-06
2023-10-25 11:34:35 ==> Last Model saved (best loss 39.5250 at epoch 12)
2023-10-25 11:34:35 ==> ------------------Epoch: 14------------------
2023-10-25 12:33:04 ==> Epoch 14 Train Loss: 24.853363929432817
2023-10-25 12:39:28 ==> Epoch 14 Val Loss: 109.03162331553176 Learning Rate: 3.276800000000002e-06
2023-10-25 12:39:28 ==> Last Model saved (best loss 39.5250 at epoch 12)
2023-10-25 12:39:28 ==> ------------------Epoch: 15------------------
2023-10-25 13:36:29 ==> Epoch 15 Train Loss: 24.828800475224853
2023-10-25 13:42:46 ==> Epoch 15 Val Loss: 40.64447140786797 Learning Rate: 2.6214400000000015e-06
2023-10-25 13:42:47 ==> Last Model saved (best loss 39.5250 at epoch 12)
2023-10-25 13:42:47 ==> ------------------Epoch: 16------------------
2023-10-25 14:39:58 ==> Epoch 16 Train Loss: 24.793048998108134
2023-10-25 14:46:16 ==> Epoch 16 Val Loss: 39.06035712803714 Learning Rate: 2.0971520000000012e-06
2023-10-25 14:46:17 ==> Epoch 16 Best Model Saved
2023-10-25 14:46:17 ==> Last Model saved (best loss 39.0604 at epoch 16)
2023-10-25 14:46:17 ==> ------------------Epoch: 17------------------
2023-10-25 15:43:02 ==> Epoch 17 Train Loss: 24.68694888812024
2023-10-25 15:49:19 ==> Epoch 17 Val Loss: 38.98785361088812 Learning Rate: 1.6777216000000011e-06
2023-10-25 15:49:20 ==> Epoch 17 Best Model Saved
2023-10-25 15:49:20 ==> Last Model saved (best loss 38.9879 at epoch 17)
